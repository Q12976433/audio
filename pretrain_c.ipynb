{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\py38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "d:\\Anaconda\\envs\\py38\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "d:\\Anaconda\\envs\\py38\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from network import ShuffleNetV2\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mobilenetv2 import mobilenetv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size is  1.5x\n"
     ]
    }
   ],
   "source": [
    "model=ShuffleNetV2(model_size='1.5x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=torch.load('./shuffle/ShuffleNetV2.1.5x.pth.tar')[\"state_dict\"]\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in sd.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1,3,224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net=mobilenetv2()\n",
    "net.load_state_dict(torch.load('mobilenetv2.pth'))\n",
    "net(torch.randn(1,3,224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_wavs(path):\n",
    "    wavs = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                wavs.append(os.path.join(root, file))\n",
    "    return wavs\n",
    "\n",
    "path_c='./illness/cough'\n",
    "path_r='./illness/respiratory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    return int(path.split('\\\\')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  axs.set_title(title or 'Spectrogram (db)')\n",
    "  axs.set_ylabel(ylabel)\n",
    "  axs.set_xlabel('frame')\n",
    "  im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n",
    "  #im = axs.imshow(spec, origin='lower', aspect=aspect)\n",
    "  if xmax:\n",
    "    axs.set_xlim((0, xmax))\n",
    "  fig.colorbar(im, ax=axs)\n",
    "  plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_r(wav):\n",
    "    spec = librosa.feature.melspectrogram(wav, sr=16000, n_fft=400, hop_length=160, n_mels=128)\n",
    "    return spec\n",
    "\n",
    "def spectrogram_c(wav):\n",
    "    spec = librosa.feature.melspectrogram(wav, sr=16000, n_fft=400, hop_length=160, n_mels=128)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class c_dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.wavs = get_all_wavs(path)\n",
    "        self.labels = [get_label(wav) for wav in self.wavs]\n",
    "    def __len__(self):\n",
    "        return len(self.wavs)\n",
    "    def __getitem__(self, idx):\n",
    "        wav, sr = torchaudio.load(self.wavs[idx])\n",
    "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "        wav = resampler(wav)\n",
    "        wav = wav[0].numpy()\n",
    "        wav = spectrogram_c(wav)\n",
    "       \n",
    "        if wav.shape[1] < 128:\n",
    "            wav = np.pad(wav, ((0, 0), (0, 128 - wav.shape[1])), 'constant')\n",
    "        else:\n",
    "            wav = wav[:, :128]\n",
    "        #resize to 224\n",
    "        wav = transforms.Resize((224, 224))(torch.from_numpy(wav).unsqueeze(0)).numpy()\n",
    "\n",
    "        #channel X3\n",
    "        wav = np.repeat(wav, 3, axis=0)\n",
    "        return torch.from_numpy(wav), self.labels[idx]\n",
    "\n",
    "class r_dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.wavs = get_all_wavs(path)\n",
    "        self.labels = [get_label(wav) for wav in self.wavs]\n",
    "    def __len__(self):\n",
    "        return len(self.wavs)\n",
    "    def __getitem__(self, idx):\n",
    "        wav, sr = torchaudio.load(self.wavs[idx])\n",
    "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "        wav = resampler(wav)\n",
    "        wav = wav[0].numpy()\n",
    "        wav = spectrogram_r(wav)\n",
    "        #extract 128 segments from center\n",
    "        if wav.shape[1] < 128:\n",
    "            wav = np.pad(wav, ((0, 0), (0, 128 - wav.shape[1])), 'constant')\n",
    "        else:\n",
    "            wav = wav[:, (wav.shape[1] - 128) // 2:(wav.shape[1] - 128) // 2 + 128]\n",
    "        wav = transforms.Resize((224, 224))(torch.from_numpy(wav).unsqueeze(0)).numpy()\n",
    "        wav = np.repeat(wav, 3, axis=0)\n",
    "        return torch.from_numpy(wav), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_c = c_dataset(path_c)\n",
    "dataset_r = r_dataset(path_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), torch.Size([3, 224, 224]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_c[0][0].shape,dataset_r[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel_c(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net1 = ShuffleNetV2(model_size='1.5x')\n",
    "        self.net1.load_state_dict(new_state_dict)\n",
    "        self.net2 = mobilenetv2()\n",
    "        self.net2.load_state_dict(torch.load('mobilenetv2.pth'))\n",
    "        self.classifier =nn.Sequential(\n",
    "            nn.Linear(2000, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x1 = self.net1(x)\n",
    "        x2 = self.net2(x)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "class mymodel_r(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net1 = ShuffleNetV2(model_size='1.5x')\n",
    "        self.net1.load_state_dict(new_state_dict)\n",
    "        self.net2 = mobilenetv2()\n",
    "        self.net2.load_state_dict(torch.load('mobilenetv2.pth'))\n",
    "        self.classifier =nn.Sequential(\n",
    "            nn.Linear(2000, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x1 = self.net1(x)\n",
    "        x2 = self.net2(x)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size is  1.5x\n"
     ]
    }
   ],
   "source": [
    "model_c=mymodel_c().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=16\n",
    "#seperate the dataset into train and test 0.8 and 0.2\n",
    "train_size=int(0.8*len(dataset_c))\n",
    "test_size=len(dataset_c)-train_size\n",
    "train_dataset,test_dataset=torch.utils.data.random_split(dataset_c,[train_size,test_size])\n",
    "train_loader=DataLoader(train_dataset,batch_size=bs,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=bs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model_c.parameters(),lr=1e-3)\n",
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_fn, optimizer):\n",
    "    size = len(train_loader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 30 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(model, test_loader, loss_fn):\n",
    "    size = len(test_loader.dataset)\n",
    "    num_batches = len(test_loader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.843217  [    0/ 1552]\n",
      "loss: 0.495416  [  480/ 1552]\n",
      "loss: 0.415406  [  960/ 1552]\n",
      "loss: 0.285926  [ 1440/ 1552]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.512057 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.258874  [    0/ 1552]\n",
      "loss: 0.502637  [  480/ 1552]\n",
      "loss: 0.532950  [  960/ 1552]\n",
      "loss: 0.273588  [ 1440/ 1552]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.458386 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.170033  [    0/ 1552]\n",
      "loss: 0.532906  [  480/ 1552]\n",
      "loss: 0.371989  [  960/ 1552]\n",
      "loss: 0.280025  [ 1440/ 1552]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.504642 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.300450  [    0/ 1552]\n",
      "loss: 0.675066  [  480/ 1552]\n",
      "loss: 0.300466  [  960/ 1552]\n",
      "loss: 0.526277  [ 1440/ 1552]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.432537 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.319523  [    0/ 1552]\n",
      "loss: 0.289316  [  480/ 1552]\n",
      "loss: 0.318475  [  960/ 1552]\n",
      "loss: 0.525565  [ 1440/ 1552]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.462178 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(model_c, train_loader, loss_fn, optimizer)\n",
    "    test(model_c, test_loader, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_c.state_dict(), 'model_c.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7763496143958869\n",
      "specificity: 0.9423076923076923\n",
      "sensitivity: 0.6652360515021459\n"
     ]
    }
   ],
   "source": [
    "#calculate the accuracy,specificity,sensitivity on the test dataset\n",
    "def score(model,test_dataset):\n",
    "    model.eval()\n",
    "    correct=0\n",
    "    tp=0\n",
    "    tn=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_dataset)):\n",
    "            X,y=test_dataset[i]\n",
    "            X=X.unsqueeze(0)\n",
    "            X=X.to(device)\n",
    "            #y=y.to(device)\n",
    "            pred=model(X)\n",
    "            if pred.argmax(1)==y:\n",
    "                correct+=1\n",
    "            if pred.argmax(1)==1 and y==1:\n",
    "                tp+=1\n",
    "            if pred.argmax(1)==0 and y==0:\n",
    "                tn+=1\n",
    "            if pred.argmax(1)==1 and y==0:\n",
    "                fp+=1\n",
    "            if pred.argmax(1)==0 and y==1:\n",
    "                fn+=1\n",
    "    accuracy=correct/len(test_dataset)\n",
    "    specificity=tn/(tn+fp)\n",
    "    sensitivity=tp/(tp+fn)\n",
    "    return accuracy,specificity,sensitivity\n",
    "\n",
    "accuracy,specificity,sensitivity=score(model_c,test_dataset)\n",
    "print('accuracy:',accuracy)\n",
    "print('specificity:',specificity)\n",
    "print('sensitivity:',sensitivity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
